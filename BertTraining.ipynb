{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e868c1",
   "metadata": {},
   "source": [
    "# Fine tuning of BERT model for labeling job resumes (1st screening)\n",
    "\n",
    "For the first part of the screening of resumes, we wanted to multilabel the target resume with the job categories.\n",
    "From the research we conducted, we agreed on fine tuning a BERT transformer model, which could yield amazing results, without having to train our own Natural Language processing model or LLM from scratch\n",
    "\n",
    "To be able to use a model like BERT on text inputs, we would need to embed the text into something it could understand.\n",
    "We therefore chose to use the BERT tokenizer, which is particularly effective for this project because it uses WordPiece tokenization, which allows it to handle out-of-vocabulary words and rare terms by breaking them into subword units. This is especially valuable when processing resumes, which often contain technical terminology. By preserving semantic meaning even in fragmented or unfamiliar words, the BERT tokenizer ensures that important contextual information from resumes is retained and properly interpreted by the model during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# We use the transformers and torch libraries for fine tuning the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a53f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pickled dataset\n",
    "import pickle\n",
    "with open('Data/Dataframes/newDF.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop all the columns that are not the resume texts or onehot encoded for the specific job categories\n",
    "trainingDF = df.drop(columns=['ID', 'Label', 'TextLen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the tokenizer used to train the bert-base-uncased model\n",
    "# This tokenizer is used to convert the text into tokens that the BERT model can understand\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc294ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset class for handling resume data\n",
    "# This is the class that will handle the embedding of the text and the labels\n",
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with input texts, their corresponding labels, \n",
    "        a tokenizer (e.g., BERT tokenizer), and the maximum token length.\n",
    "\n",
    "        Args:\n",
    "            texts: List of resume texts.\n",
    "            labels: Multi-label targets for each resume.\n",
    "            tokenizer: Tokenizer to convert text to model input format.\n",
    "            max_len: Maximum token length for each input. Its set at default to 512 tokens.\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Tokenizes and processes a single sample for the model.\n",
    "\n",
    "        Args:\n",
    "            idx: Index of the sample.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary with tokenized input tensors and labels.\n",
    "        \"\"\"\n",
    "        # Tokenize the input text with truncation and padding to max length\n",
    "        # The truncation is set to True to ensure that the text is cut off at the max length\n",
    "        # This is done to ensure that the model does not receive more than 512 tokens, which is the maximum length for BERT\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'  # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Remove batch dimension from returned tensors\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "\n",
    "        # Convert label list to a float tensor, which is required for multi-label classification\n",
    "        # The labels are converted to a tensor of floats, as the model expects the labels to be in this format\n",
    "        # The labels are the one-hot encoded vectors for the specific job categories\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1767e7",
   "metadata": {},
   "source": [
    "As we mentioned earlier, we use 512 as the max length of tokens as input for the model when training on the resumes, since that is the maximum length that Bert can handle.\n",
    "If we had more time, we could convert the resumes into subtexts to feed into Bert and therefore still keep all of the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "# We use 90% of the data for training and 10% for validation\n",
    "# The texts are the resumes and the labels are the onehot encoded job categories\n",
    "# We could have assigned more of the dataset for testing, but we did not have the time test the training of the model with different test and training sizes\n",
    "\n",
    "texts = df['Resume'].tolist()\n",
    "labels = trainingDF.drop(columns=['Resume']).values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.1)\n",
    "\n",
    "train_dataset = ResumeDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = ResumeDataset(X_val, y_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e07b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading the pre-trained BERT model for sequence classification\n",
    "# 'bert-base-uncased' refers to the base BERT model with lowercase (uncased) inputs\n",
    "# num_labels is set to the number of output classes, which is the number of job categories\n",
    "# problem_type is explicitly defined to guide the model to use a sigmoid activation function.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=labels.shape[1],\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680f8ff",
   "metadata": {},
   "source": [
    "\n",
    "#### Hyperparameters and settings for training the BERT model:\n",
    "\n",
    "We set the number of epochs to 3, which is a common choice for fine-tuning BERT. We did not have the time to test the model with more epochs.\n",
    "We are however looking at the loss and accuracy of the model after each epoch, so we can see if the model is overfitting or not.\n",
    "\n",
    "We set the batch size to 8, which is a common choice for fine-tuning BERT. We started with a batch size of 16, but the model was running out of memory.\n",
    "Although we used the AdamW optimizer, which adapts learning rates per parameter, we did not apply a dynamic learning rate schedule during training. Implementing such a scheduler could further optimize the model during training, but we did not have the time to test it.\n",
    "Lastly we use cuda for training the model if it is available, which reduced the training time from 20 hours to 2 hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c1e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import accelerate\n",
    "print(accelerate.__version__)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3f7011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9771' max='9771' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9771/9771 2:17:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.029585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.021991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.018065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9771, training_loss=0.03867846989406366, metrics={'train_runtime': 8241.5805, 'train_samples_per_second': 9.483, 'train_steps_per_second': 1.186, 'total_flos': 2.0565184708583424e+16, 'train_loss': 0.03867846989406366, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30f391",
   "metadata": {},
   "source": [
    "### Training output\n",
    "\n",
    "The model was fine-tuned over 3 epochs using the BERT architecture. Training completed in approximately 2 hours and 17 minutes, with a final average training loss of 0.0387. As shown in the table below, both training and validation loss decreased steadily, indicating that the model was learning effectively without overfitting.\n",
    "\n",
    "The final validation loss of 0.0181 suggests that the model generalized well to unseen data, making it suitable for multi-label classification of resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f812d07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pelle\\Work\\1semSoft\\exam\\AIML-Exam\\examVenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./results/checkpoint-9771\\\\tokenizer_config.json',\n",
       " './results/checkpoint-9771\\\\special_tokens_map.json',\n",
       " './results/checkpoint-9771\\\\vocab.txt',\n",
       " './results/checkpoint-9771\\\\added_tokens.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To upload the model, we have to save the tokenizer and the model\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the same tokenizer you used during training\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Save it to the directory where your checkpoint is stored\n",
    "tokenizer.save_pretrained(\"./results/checkpoint-9771\")  # adjust if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5784752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# To train the model on an nvidia GPU, you need to download the CUDA toolkit and install the nvidia drivers.\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function to compute the metrics for the model\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convert logits to predicted class indices\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    # If labels are one-hot, convert to class indices too\n",
    "    if labels.ndim > 1 and labels.shape[1] > 1:\n",
    "        labels = np.argmax(labels, axis=1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b10443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the compute_metrics function to the trainer\n",
    "trainer.compute_metrics = compute_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c6d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pelle\\Work\\1semSoft\\exam\\AIML-Exam\\examVenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2e0d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018065307289361954, 'eval_accuracy': 0.8918825561312608, 'eval_precision': 0.922566883602777, 'eval_recall': 0.8918825561312608, 'eval_f1': 0.9027684731323408, 'eval_runtime': 73.8097, 'eval_samples_per_second': 39.222, 'eval_steps_per_second': 4.905, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa54a55",
   "metadata": {},
   "source": [
    "- eval_loss': 0.018065307289361954\n",
    "- eval_accuracy': 0.8918825561312608\n",
    "- eval_precision': 0.922566883602777\n",
    "- eval_recall': 0.8918825561312608\n",
    "- eval_f1': 0.9027684731323408\n",
    "- eval_runtime': 73.8097\n",
    "- eval_samples_per_second': 39.222\n",
    "- eval_steps_per_second': 4.905\n",
    "- epoch': 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab916b",
   "metadata": {},
   "source": [
    "## Evaluation Summary (After Final Epoch)\n",
    "\n",
    "\n",
    "eval_loss: 0.0181\n",
    "A low loss value on the validation set suggests that the model has learned the task well and generalizes effectively to unseen data. This is a positive indicator and shows that the model did not overfit during training.\n",
    "\n",
    "eval_accuracy: 89.19%\n",
    "This is a strong result; however, accuracy alone can be misleading in multi-label classification, where multiple correct labels may exist for each sample. This is the metric that calculates the amount of times BERT was 100% correct on the labeling.\n",
    "\n",
    "eval_precision: 92.26%\n",
    "This high value indicates that when the model predicts a label, it is correct most of the time. This is especially important in screening tasks, where false positives (irrelevant matches) should be minimized.\n",
    "\n",
    "eval_recall: 89.19%\n",
    "The model is also successful at capturing most of the correct labels, which means it rarely misses relevant job categories. A high recall is crucial to ensure that no important skills or qualifications are overlooked.\n",
    "\n",
    "eval_f1: 90.28%\n",
    "The F1 score balances both precision and recall. A score above 90% reflects excellent overall performance and confirms that the model handles the trade-off between false positives and false negatives well.\n",
    "\n",
    "## Evaluation Efficiency\n",
    "Runtime: around 74 seconds\n",
    "\n",
    "Samples per second: 39.22\n",
    "\n",
    "Steps per second: 4.91\n",
    "\n",
    "These metrics indicate that the model evaluates data quickly and efficiently. Processing nearly 40 samples per second shows that the system would be capable of real-time or batch-mode screening in practical HR applications.\n",
    "\n",
    "## Interpretation\n",
    "Overall, the model performs very well on the task of resume classification:\n",
    "\n",
    "High F1 score, precision, and recall show the model is both accurate and comprehensive in identifying relevant job categories.\n",
    "\n",
    "Low loss and consistent performance over epochs suggest good generalization and stable training.\n",
    "\n",
    "Fast evaluation speed means the system could scale to large datasets in a real-world scenario.\n",
    "\n",
    "There are no major signs of overfitting or instability, and the performance is strong across multiple metrics. These results indicate that the model is well-suited for first-round automated resume screening in a multi-label setting.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "examVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
